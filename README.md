Для корректной работы кода в одной папке с ним должны находиться файлы с данными. Из-за ограничения на github по объему их можно скачать для проверки здесь:
https://drive.google.com/drive/folders/1OJioCpZPYjh6WkF6XSyhR5TZLPHxCdFP?usp=sharing
**Исходные данные:**
Поскольку я не изучал ранее машинное обучение вообще и совершенно ничего не знал о предобработке текста, Naive Bayes и пр., задание было непростым (+ не было времени на ошибки, работал несколько часов по вечерам, завершая другие взятые задачи параллельно). API пользовался, но сам не создавал. Результат:

**Создан скрипт для обработки текста (файл 1)**
Предполагается, что csv-файл с данными лежит в той же папке и имеет поле "comment_text". Кастомизировать метод не стал для данной задачи. С помощью библиотеки re удаляются числа, даты, ссылки, знаки препинания, с помощью библиотеки nltk осуществляется удаление стоп-слов и лемматизация
**Строится график 10 самых частых слов (файл 2)**
На основе библиотеки nltk создается частотное распределение слов и рисуется простой график. Подразумевается наличие файла"word_tokens.csv" в папке. Далее можно настроить график в зависимости от целей по длине слов и т.п. (в папке есть пример результата)
**Создана модель с помощью наивного байесовского классификатора (файл 3):**
Самая сложная часть ввиду отсутствие знаний по машинному обучению, азы учились прямо во время выполнения задания. Ввиду ограничения памяти компьютера, взял 20% выборки, обучил на них модель с разбиением данных на обучающие и тестовые. 
Результат (есть скриншот): Accuracy  0,933, F1 score 0,777
Думаю, можно было бы обходить ограничения памяти, если использовать библиотеку joblib и делать пакетную обработку.
**Построение API и тестирование (файл 4 + Tester.py)**
Сделал API c помощью Flask, настроенное на локальном сервере. Принимает и возвращает ответ.
Возникла сложность, которую я не смог решить: модель принимает числовые данные, и если отправлять ей соответствующую матрицу – то на Tester возвращается ответ, но нам надо работать с текстом. А при построении CountVectorizer() формируется словарь слов, который несопоставим со словарём обученной модели.  Поэтому в заданный срок корректного результата добиться не удалось, если это надо для дальнейших задач – буду учиться.
